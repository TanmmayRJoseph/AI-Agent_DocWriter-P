{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Doc Writer Ai Agent",
   "id": "b016cdca39e4d3ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T07:42:43.491447Z",
     "start_time": "2025-07-13T07:42:43.486297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.schema import HumanMessage\n",
    "from typing import Optional, TypedDict\n"
   ],
   "id": "a42dc57101199950",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T07:42:43.554625Z",
     "start_time": "2025-07-13T07:42:43.529230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key from environment variable\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Check and print status\n",
    "print(\"API key loaded successfully!\" if GOOGLE_API_KEY else \"API key not found!\")"
   ],
   "id": "f8703f76d270c4d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully!\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T07:42:43.647042Z",
     "start_time": "2025-07-13T07:42:43.582248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# make sure to set the GOOGLE_API_KEY in your .env file\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash-latest\",\n",
    "    temperature=0.5,\n",
    "    google_api_key=GOOGLE_API_KEY\n",
    ")\n",
    "# making sure llm is working add a print statement\n",
    "print(\"LLM initialized successfully!\")"
   ],
   "id": "d39a19c2189cb8dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized successfully!\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T07:42:43.674040Z",
     "start_time": "2025-07-13T07:42:43.663465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# defining the AgentState class\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"State of the agent.\"\"\"\n",
    "    topic: str  # Topic of the document/email\n",
    "    draft: Optional[str]  # Current draft generated/refined\n",
    "    feedback: Optional[str]  # Feedback from human (if any)\n",
    "    is_satisfied: Optional[bool]  # Whether human is happy with the draft"
   ],
   "id": "5abcc1c806c0c8c9",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T07:42:43.703295Z",
     "start_time": "2025-07-13T07:42:43.695640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ai_node(s: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Generates or refines a document draft based on the topic or existing draft.\n",
    "\n",
    "    This node checks if a draft already exists in the state. If not, it prompts\n",
    "    the LLM to generate a new document based on the provided topic. If a draft\n",
    "    exists, it asks the LLM to refine the current draft. The resulting content\n",
    "    is stored in the 'draft' key of the state.\n",
    "\n",
    "    Args:\n",
    "        s (AgentState): The current state of the agent containing at least a 'topic',\n",
    "                        and optionally a 'draft'.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: The updated state with a new or refined 'draft'.\n",
    "    \"\"\"\n",
    "    if s['draft'] is None:\n",
    "        prompt = f\"Write a document about {s['topic']}.\"\n",
    "    else:\n",
    "        prompt = f\"Refine the following document: {s['draft']}\"\n",
    "\n",
    "    # Simulate typing/processing\n",
    "    print(\"ðŸ§  Generating response\", end=\"\", flush=True)\n",
    "    for _ in range(3):\n",
    "        time.sleep(0.5)\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    llm.invoke([HumanMessage(content=prompt)])\n",
    "\n",
    "    s['draft'] = response.content\n",
    "    return s"
   ],
   "id": "76c280d43dfb5a64",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T07:42:43.726596Z",
     "start_time": "2025-07-13T07:42:43.721119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def show_to_human(s: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Displays the generated draft to the user and collects satisfaction feedback.\n",
    "\n",
    "    This node prints the current 'draft' to the console and prompts the user with\n",
    "    a yes/no question after a short pause.\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ“ Draft:\\n{s['draft']}\\n\")\n",
    "\n",
    "    # Optional delay before asking\n",
    "    print(\"Processing complete. Preparing to ask for your feedback...\")\n",
    "    time.sleep(10)  # wait for 2.5 seconds\n",
    "\n",
    "    feedback = input(\"Are you satisfied with the draft? (yes/no): \").strip().lower()\n",
    "\n",
    "    s['is_satisfied'] = True if feedback == \"yes\" else False\n",
    "    return s\n"
   ],
   "id": "27da494fab142e55",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T07:42:43.747728Z",
     "start_time": "2025-07-13T07:42:43.741350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def take_feedback(s: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Prompts the human user for feedback if the draft is unsatisfactory.\n",
    "\n",
    "    If 'is_satisfied' is False, this node asks the user to provide feedback\n",
    "    on how the draft can be improved. The feedback is stored in the 'feedback'\n",
    "    key of the state. If the user is satisfied, any existing feedback is cleared.\n",
    "\n",
    "    Args:\n",
    "        s (AgentState): The current agent state, including satisfaction status.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: The updated state with 'feedback' set to user input or None.\n",
    "    \"\"\"\n",
    "    if not s['is_satisfied']:\n",
    "        feedback = input(\"Please provide your feedback on the draft: \")\n",
    "        s['feedback'] = feedback\n",
    "    else:\n",
    "        s['feedback'] = None  # Clear feedback if satisfied\n",
    "\n",
    "    print(f\"Feedback recorded: {s['feedback']}\")\n",
    "    return s\n"
   ],
   "id": "2af7efb0eaff1135",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T07:42:43.771165Z",
     "start_time": "2025-07-13T07:42:43.765229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def refine_node(s: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Refines the current draft based on human feedback using the LLM.\n",
    "    \"\"\"\n",
    "    if s['feedback'] is not None:\n",
    "        prompt = (\n",
    "            f\"Please revise the following draft to better address the feedback provided. \"\n",
    "            f\"Be clear, concise, and accurate.\\n\\n\"\n",
    "            f\"Feedback: {s['feedback']}\\n\\n\"\n",
    "            f\"Original Draft:\\n{s['draft']}\"\n",
    "        )\n",
    "\n",
    "        print(\"ðŸ§  Refining draft\", end=\"\", flush=True)\n",
    "        for _ in range(3):\n",
    "            time.sleep(0.5)\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        response = llm.invoke(prompt)  # âœ… Pass as plain string\n",
    "        s['draft'] = f\"Refined Draft:\\n{response.content}\"\n",
    "    else:\n",
    "        print(\"No feedback provided, skipping refinement.\")\n",
    "\n",
    "    return s\n"
   ],
   "id": "2afd6355dac82eeb",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T07:42:43.790880Z",
     "start_time": "2025-07-13T07:42:43.782956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "def save_draft(s: AgentState):\n",
    "    \"\"\"\n",
    "    Saves the final approved draft and optional feedback to a text file.\n",
    "\n",
    "    If the draft has been approved (is_satisfied is True), this node creates a\n",
    "    timestamped .txt file containing the topic, draft, and feedback. Otherwise,\n",
    "    it prints a message that the draft was not saved.\n",
    "\n",
    "    Args:\n",
    "        s (AgentState): The final state containing 'topic', 'draft', and 'feedback'.\n",
    "    \"\"\"\n",
    "    if s.get('is_satisfied') == True:\n",
    "        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f\"final_draft_{timestamp}.txt\"\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"Topic: {s.get('topic', 'Unknown')}\\n\\n\")\n",
    "            f.write(f\"Draft:\\n{s.get('draft', 'No draft')}\\n\\n\")\n",
    "            f.write(f\"Feedback: {s.get('feedback', 'No feedback provided')}\\n\")\n",
    "        print(f\"âœ… Draft saved as {filename} in {os.getcwd()}\")\n",
    "    else:\n",
    "        print(\"âŒ Draft not saved as it was not approved by the user.\")\n"
   ],
   "id": "229eccf03c180181",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T07:42:43.822596Z",
     "start_time": "2025-07-13T07:42:43.803073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add all your nodes\n",
    "workflow.add_node(\"ai_draft\", ai_node)\n",
    "workflow.add_node(\"show_to_human\", show_to_human)\n",
    "workflow.add_node(\"take_feedback\", take_feedback)\n",
    "workflow.add_node(\"refine_draft\", refine_node)\n",
    "workflow.add_node(\"save_draft\", save_draft)\n",
    "\n",
    "# Add edges\n",
    "workflow.set_entry_point(\"ai_draft\")\n",
    "workflow.add_edge(\"ai_draft\", \"show_to_human\")\n",
    "\n",
    "\n",
    "# Conditional branch based on satisfaction\n",
    "def condition(state: AgentState) -> str:\n",
    "    return \"save_draft\" if state[\"is_satisfied\"] else \"take_feedback\"\n",
    "\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"show_to_human\",\n",
    "    condition,\n",
    "    {\n",
    "        \"save_draft\": \"save_draft\",\n",
    "        \"take_feedback\": \"take_feedback\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Continue loop if not satisfied\n",
    "workflow.add_edge(\"take_feedback\", \"refine_draft\")\n",
    "workflow.add_edge(\"refine_draft\", \"ai_draft\")\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n"
   ],
   "id": "891dcefe0836d463",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "initial_state = {\n",
    "    \"topic\": \"The impact of AI Healthcare\",\n",
    "    \"draft\": None,\n",
    "    \"feedback\": None,\n",
    "    \"is_satisfied\": None\n",
    "}\n",
    "final_state = app.invoke(initial_state)"
   ],
   "id": "7c59f7b27f3c1733",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "138d9dd369c281d2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
